{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import collections\n",
    "import sklearn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataset\n",
    "df = pd.read_csv('animelists.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>21</td>\n",
       "      <td>586</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:52:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 13:54:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27 16:43:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:53:57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-27 15:59:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   username  anime_id  my_watched_episodes my_start_date my_finish_date  \\\n",
       "0  karthiga        21                  586    0000-00-00     0000-00-00   \n",
       "1  karthiga        59                   26    0000-00-00     0000-00-00   \n",
       "2  karthiga        74                   26    0000-00-00     0000-00-00   \n",
       "3  karthiga       120                   26    0000-00-00     0000-00-00   \n",
       "4  karthiga       178                   26    0000-00-00     0000-00-00   \n",
       "\n",
       "   my_score  my_status  my_rewatching  my_rewatching_ep      my_last_updated  \\\n",
       "0         9          1            NaN                 0  2013-03-03 10:52:53   \n",
       "1         7          2            NaN                 0  2013-03-10 13:54:51   \n",
       "2         7          2            NaN                 0  2013-04-27 16:43:35   \n",
       "3         7          2            NaN                 0  2013-03-03 10:53:57   \n",
       "4         7          2            0.0                 0  2013-03-27 15:59:13   \n",
       "\n",
       "  my_tags  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Overview of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a smaller dataset for the model and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~pd.isnull(df['username'])]\n",
    "good_users = df['username'].value_counts()\n",
    "good_users = good_users[good_users >20]\n",
    "good_user_ids = good_users.index.values\n",
    "\n",
    "import random\n",
    "user_ids = random.sample(list(good_user_ids), 300)\n",
    "\n",
    "full_data_filtered = df[df['username'].isin(user_ids)]\n",
    "full_data_filtered.shape\n",
    "anime_ids = full_data_filtered['anime_id'].value_counts()\n",
    "anime_ids = anime_ids[(anime_ids > 20) & (anime_ids <250)]\n",
    "\n",
    "anime_ids = anime_ids.index.values\n",
    "\n",
    "full_data_filtered2 = full_data_filtered[full_data_filtered['anime_id'].isin(anime_ids)]\n",
    "full_data_filtered2['my_score'] = np.where(full_data_filtered2['my_score'] == 0 ,1,full_data_filtered2['my_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering the columns of interest for the model\n",
    "df_filtered = full_data_filtered2.loc[:,['username','anime_id','my_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>kioniel</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>kioniel</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>kioniel</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>kioniel</td>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>kioniel</td>\n",
       "      <td>249</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username  anime_id  my_score\n",
       "4566  kioniel        21         9\n",
       "4567  kioniel        59         9\n",
       "4568  kioniel       210         9\n",
       "4569  kioniel       232         2\n",
       "4570  kioniel       249         7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is how the final dataset looks like\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_filtered, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigen Rank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_order_greedy(rating, test, user_id):\n",
    "    '''Estimate the potential for each anime in the anime list watched by the neighbors\n",
    "        and rank them using greedy order approach'''\n",
    "    \n",
    "    pie = {}\n",
    "    rank = {}\n",
    "    rank[9999] = -1\n",
    "    my_neighbours, Item_list = Neighb(user_id, rating, test)\n",
    "\n",
    "    for i in Item_list:\n",
    " \n",
    "        second_list = Item_list.copy()\n",
    "        second_list.remove(i)\n",
    "        for j in second_list:\n",
    " \n",
    "            pie[i] = preference_func(i, j, user_id, rating,my_neighbours) - preference_func(j, i, user_id, rating,my_neighbours)\n",
    "\n",
    "    while ((len(Item_list) > 0) and (len(pie) > 0)):\n",
    "        t = max(pie.items(), key = operator.itemgetter(1))[0]\n",
    "\n",
    "        rank[t] = len(Item_list)\n",
    "        Item_list.remove(t)\n",
    "        pie.pop(t, None)\n",
    " \n",
    "        for k in Item_list:\n",
    "\n",
    "            pie[k]= pie[k] + preference_func(t,k, user_id, rating,my_neighbours) - preference_func(k,t, user_id, rating,my_neighbours)\n",
    "\n",
    "    return get_n_longest_values_g(rank)\n",
    "\n",
    "def get_n_longest_values_g(dictionary, n = 10):\n",
    "    ''' Outputs the top N anime recommendations for each target user'''\n",
    "    \n",
    "    longest_entries = sorted(\n",
    "        dictionary.items(), key=lambda t: t[1], reverse=True)[:n]\n",
    "    return [key[0] for key in longest_entries]\n",
    "\n",
    "\n",
    "def Neighb(user_id, rating, test, cutoff = 10):\n",
    "    '''Finds the top N neighbors for a target user based on its similarity score with other users. Here N = 10 \n",
    "        Similarity scores are calculated using kendall tau coefficeint'''\n",
    "    \n",
    "    anime_remove = rating[rating['username'] == user_id]['anime_id']\n",
    "    rating = rating[~rating['anime_id'].isin(anime_remove)]\n",
    "    all_users = list(rating['username'])\n",
    "\n",
    "    neighb_score = {}\n",
    "    Item_list = list(test.loc[test['username'] == user_id, 'anime_id'])\n",
    "    for u in all_users:\n",
    "\n",
    "        neighb_score[u] = Kendall_CC(user_id, u, rating)\n",
    "        \n",
    "    top_10 = dict(sorted(neighb_score.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "\n",
    "    return top_10, list(set(Item_list))\n",
    "\n",
    "\n",
    "def preference_func(A, B, user_id, rating, my_neighbs):\n",
    "    ''' Calculate the preference function for the neighbors of the target user (user_id) between two animes A and B '''\n",
    "\n",
    "    pf = 0.00\n",
    "    num = 0.0\n",
    "    denom = 0.0\n",
    "    for key, val in my_neighbs.items():\n",
    "\n",
    "        if(val!= 0.00):\n",
    "\n",
    "            mask1 = sum((rating['username'] == key)&(rating['anime_id'] == A))\n",
    "\n",
    "            mask2 = sum((rating['username'] == key)&(rating['anime_id'] == B))\n",
    "\n",
    "            if ((mask1 >0 )&( mask2 >0)):\n",
    "                prod = rating.loc[((rating['username'] == key)&(rating['anime_id'] == A)), 'my_score'].item() - rating.loc[((rating['username'] == key)&(rating['anime_id'] == B)), 'my_score'].item()     \n",
    "\n",
    "                num = num + prod*val\n",
    "                denom = denom+val\n",
    "    if(denom > 0):\n",
    "        pf = num/denom\n",
    "\n",
    "    return pf\n",
    "\n",
    "\n",
    "def indicator_f(x):\n",
    "    ''' Indicates if the two users have rated anime i more than anime j or vice versa. If yes returns zero else 1'''\n",
    "    \n",
    "    if(x <0):\n",
    "        r = 1\n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "def Kendall_CC(u_id, v_id, df):\n",
    "    '''This function calculates the similarity coefficient between two users using kendall tau'''\n",
    "    \n",
    "    S = 0\n",
    "    \n",
    "    user_anm_rating = pd.merge(df[df['username'] == u_id], df[df['username'] == v_id], on='anime_id', how='inner', \\\n",
    "                               suffixes={'_U', '_V'})\n",
    "    \n",
    "    if(len(user_anm_rating)>5):\n",
    "        val = 0\n",
    "        for a in range(len(user_anm_rating)-1):\n",
    "\n",
    "            e = (user_anm_rating.loc[a,'my_score_U'] - user_anm_rating.loc[a+1,'my_score_U'])*(user_anm_rating.loc[a,'my_score_V'] - user_anm_rating.loc[a+1,'my_score_V'])\n",
    "\n",
    "            val = val + indicator_f(e)\n",
    "\n",
    "        S = 1-4*(val/(len(user_anm_rating)*(len(user_anm_rating)-1)))\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call the Greedy Order Algorithm for each user in the dataset\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "for i in test['username'].unique():\n",
    "    my_rank = []\n",
    "    my_rank = calculate_order_greedy(train, test, i)\n",
    "    rank_output = pd.DataFrame(v for v in my_rank) \n",
    "    rank_output['predict_rank'] = np.arange(1, len(rank_output) + 1)\n",
    "    rank_output['username'] = i\n",
    "    df_final = df_final.append(rank_output)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"time elapsed for one user and all operations\", i, elapsed_time, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the output of the algorithm with the test data\n",
    "final_df = test.merge(df_final, how = 'inner', left_on = ['anime_id','username'], right_on = [0,'username'] )\n",
    "final_df.drop([0],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_score</th>\n",
       "      <th>predict_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waaaaaaah</td>\n",
       "      <td>21881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negshmeg</td>\n",
       "      <td>8424</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tennou</td>\n",
       "      <td>205</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KuroKagami</td>\n",
       "      <td>7311</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boundby</td>\n",
       "      <td>5525</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username  anime_id  my_score  predict_rank\n",
       "0   waaaaaaah     21881         1             1\n",
       "1    negshmeg      8424         1             8\n",
       "2      Tennou       205         9             7\n",
       "3  KuroKagami      7311         1             8\n",
       "4     Boundby      5525         9             9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is how the final dataframe with original rating and predicted rank looks like\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will evaluate our alogirthm using two metrics : Normalized Discounted Cumulative gain (NDCG) and Mean Average Precision(MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_apm(mydf):\n",
    "    '''It calculates ndcg for each user and then averages it to get an overall NDCG. This function checks if the\n",
    "        predcited rank is similar to the actual ranking based on the ratings given by the users'''\n",
    "    dcg = 0.0\n",
    "    ndcg = 0.0\n",
    "    for i in mydf['username'].unique():\n",
    "\n",
    "        user_df = mydf[mydf['username'] == i]\n",
    "        ideal_dcg = 0.0\n",
    "        y_true_sorted = sorted(user_df['my_score'], reverse=True)\n",
    "\n",
    "        for j in range(user_df.shape[0]):\n",
    "\n",
    "            ideal_dcg = ideal_dcg + (2 ** y_true_sorted[j] - 1.) / np.log2(j + 2)\n",
    "\n",
    "        dcg = 0.0\n",
    "        for kk in range(user_df.shape[0]):\n",
    "\n",
    "            dcg = dcg + (2**(user_df.iloc[kk, 2]) - 1.0)/ np.log2(1+user_df.iloc[kk, 3])\n",
    "\n",
    "        ndcg += dcg/ideal_dcg\n",
    "\n",
    "    res = ndcg/(mydf['username'].nunique())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the NDCG function and print the result\n",
    "output = ndcg_apm(final_df)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mark animes as relevant and recommend based on the threshold \n",
    "threshold = 8\n",
    "final_df['relevant'] = np.where(final_df['my_score'] > threshold, 1,0)\n",
    "final_df['recommended'] = np.where(final_df['predict_rank'] > threshold, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP_k(mydf, k=10):\n",
    "    ''' This function evaluates that how many of the recommended items to a user are relevant to him\n",
    "        It then averages MAP value for each user to get an overall measure'''\n",
    "    \n",
    "    AP = 0.0\n",
    "    for i in mydf['username'].unique():\n",
    "\n",
    "        user_df = mydf[mydf['username'] == i]\n",
    "        user_df.sort_values('predict_rank', axis=0, inplace=True, ascending=False)\n",
    "        top_N_items = user_df['recommended'].values[:k+1]\n",
    "\n",
    "        p_list = np.empty((0,k), int)\n",
    "        for j in range(len(top_N_items)):\n",
    "            l = user_df['recommended'].values[:j+1]\n",
    "            val = np.sum(l)/len(l)\n",
    "            p_list = np.append(p_list, val)\n",
    "\n",
    "        sum_val = sum(p_list * top_N_items)\n",
    "        if(sum(user_df['relevant'] >0)):\n",
    "            AP = AP + sum_val/sum(user_df['relevant'])\n",
    "    MAP = AP/mydf['username'].nunique()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the MAP function and print the result\n",
    "map_output = MAP_k(final_df)\n",
    "map_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
